{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone #2 Data Description\n",
    "\n",
    "### By: Paul Harris, Mitchell Foster, Luke Morgan-Scott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Imbalanced Nature of the data \n",
    "   ##### So there are a few issues deterring us from a simple application of machine learning algorithms to this data, the most salient being the existence of multiple genres for certain movies. Right now, think that taking a three-fold approach makes sense. The first step is removing observations for which there is no genre information at all (plenty of data with non-missing genre information). The second step involved genre coordination across the two databases (The genre's for IMDb and TMDb movies do not match one-to-one, thus we approached this problem by coercing the imdb genre list to the tmdb list through merging certain categories such as 'News' with 'Documentary' --seems reasonable! -- and creating new ones to deal with genre groupings -- Romance-Comedy) The third step was dealing with variable lengths in our movie genres. This was interesting. No approach to this will be infallible so we imposed some assumptions. We restrict ourselves to looking at the most prevalent genres in the movie's genre list. Then we take the top two genres -- this is motivated by the fact that only keeping one genre destroys TOO much classifying information, while three may be a bit excessive. There is a distinct difference between A Comedy, a Romance-Comedy, and a Romance-Comedy-Drama. A simple comedy is too broad. Everybody knows what a Rom-Com is, though. And do we necessarily get more information by saying that a Rom-Com is also a Drama? If the length is greater than three (Romance, Comedy, Action) we take the most prevalent two genres. \n",
    "\n",
    "\n",
    "* Description of your data\n",
    "    ##### 6000+ observations of movies from both databases (One metadata, one poster info). X is 6 length list of features, with a few additional columns like ID, etc. Y is the 'adjusted' genre information for each particular movie. \n",
    "    \n",
    "    \n",
    "* What does your choice of Y look like? \n",
    "    ##### Our choice of Y is the list of 19 genres from TMDb as well as additional 'intuitive' two-genre pairs such as Romance-Comedy etc. The feasibility of including certain two-genre pairs will be tested as we build models. \n",
    "    \n",
    "    \n",
    "* Which features do yo choose for X and why? \n",
    "    ##### we chose Cast, Director, plot_keywords, content_rating, budget, actor_1_name, and we may introduce additional variables later on. We chose these because certain actors appear in certain types of movies more often than all actors as a whole -- Think The Rock for Action. Certain directors direct certain movies more often than all directors - Think James Wan/M Night Shyamalan for Horror. Plot_keywords for obvious reasons. Budget, because some types of movies operate on higher/lower budgets than others -- Action vs Romance. \n",
    "    \n",
    "    \n",
    "* How do you sample your data, how many samples, and why? \n",
    "    ##### This dataset is large! Right now we have a randomized sample of around 6000 movies, due to limitations on computing resources. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
